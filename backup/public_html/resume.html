<meta name="viewport" content="width=device-width, initial-scale=1">
<!DOCTYPE html>
<html>

<head>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <!-- <script src="three.min.js"></script> -->
    <meta name="google-site-verification" content="bKn2hLTLLXTef5EmDecqfov8dA-cdLnxiA0dUtdnDvo" />
    <link rel="stylesheet" type="text/css" href="mystyle.css">
    <title>
        andy muehlhausen resume
    </title>
</head>

<body style="background-color:#FFFFFF;">
    <h1><a href="http://www.andymule.com/">andy muehlhausen</a></h1>
    <h2>
    <p>Emerging Tech Experience Designer</p>
    <p>My mission is to build meaningful human-to-human interactions that push the boundaries of technology. <br />I design, lead, and implement immersive interactive  experiences involving combinations of computers and physical interaction.</p><br />
    <p>
        <strong>Apple, Vision Products Group</strong><br /> Experience Prototyper, 2022 - Present <br />
        Design interactions for emergent products with full stack consideration. Work with all teams to ship. 
    </p>
	<p>
        <strong>Meta, Reality Labs Research</strong><br /> Audio Experience Prototyper, 2020 - 2022 <br />
        └ <a href="https://about.fb.com/news/2020/09/facebook-reality-labs-research-future-of-audio/">Audio Presence and Superhuman Hearing Experience Research</a><br />
    </p>
    <p>
        <strong>Tobii Eye-Tracking </strong><br /> Mixed Reality Eye-Tracked Interaction Designer, 2018 - 2020 <br />
        ├ <a href="https://vr.tobii.com/sdk/explore/">Tobii Interactions Showcase</a><br />
        ├ <a href="https://vr.tobii.com/sdk/develop/unity/tools/xr-dev-tools/">XR Eye Tracking Dev Tools</a><br />
        ├ <a href="https://vr.tobii.com/sdk/develop/unity/tools/gaze-modifier/">Gaze Modifier</a><br />
        ├ <a href="https://vr.tobii.com/sdk/learn/eye-behavior/visual-angles/">Explaining Visual Angles</a><br />
        └ <a href="https://vr.tobii.com/sdk/learn/eye-behavior/hardware-accuracy/">Explaining Eye Tracking Accuracy</a><br />
    </p>
    <p>
        <strong>Microsoft</strong><br /> 
        Hardware Prototyper @ Incubation Labs, 2016 - 2018 <br /> 
        Audio Experience Prototyper @ HoloLens, 2014 - 2016 <br />
        ├ <a href="https://github.com/microsoft/MixedRealityToolkit/blob/master/Input/MicStreamSelector/Source/MicStreamSelector.cpp">HoloLens Beamforming Capture Library</a><br />
        ├ <a href="https://github.com/reneschulte/HoloToolkit-Unity/blob/master/Assets/HoloToolkit/Input/Scripts/Microphone/MicStream.cs">Unity Hooks for HoloLens Beamforming Library</a><br />
        ├ <a href="https://docs.unity3d.com/Manual/VRAudioSpatializer.html">Unity Audio Spatializer Platform</a><br />
        └ <a href="https://www.audiokinetic.com/library/2017.2.10_6745/?source=Help&id=ms_hrtf_plug_in">Wwise MS HRTF Plugin</a><br />
    </p>
    <p>
        <strong>Qualcomm Institute - UCSD Division of Calit2</strong><br /> Research Assistant, 2012 - 2014<br />
        └<a href="http://yadegari.org/software/mugic/">MUGIC, Multi-User Graphics with Interactive Control</a><br />
    </p>

    <p><strong>U.S. Patents<br /> 
    </strong>
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10630965">Calibrating a near-eye display</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10674305">Remote multi-dimensional audio</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10694311">Synchronized spatial audio presentation</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10740389">Remembering audio traces of physical actions</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10481856">Volume adjustment on hinged multi-screen device</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10437336">Haptics to identify button regions</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10317505">Composite sound output for network connected devices</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10311543">Virtual object movement</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10249095">Context-based discovery of applications</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=10186086">Augmented reality control of computing device</a> <br />
    ├<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=9865091">Localizing devices in augmented reality environment</a> <br />
    └<a href="http://patft1.uspto.gov/netacgi/nph-Parser?patentnumber=9558760">Real-time remodeling of user voice </a> <br />
    </p>
    <p><strong>Education</strong> 
        <br /> University of California, San Diego (MFA), Theatre (Sound Design) &middot; (2011 - 2014) <br /> Purdue University (BS), Computer Science; Minors: Theatre, Physics &middot; (2006 - 2010)</p>
    <br />
    <a href="index.html">hide </a> - 
    <a href="media.html">personal projects</a> - 
    <a href="https://www.linkedin.com/in/andymule">linkedin</a> - 
    <a href="https://github.com/andymule">github</a>
</h2>
</body>
</html>