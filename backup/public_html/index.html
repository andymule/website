<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <script src="three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/postprocessing/EffectComposer.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/postprocessing/RenderPass.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/postprocessing/UnrealBloomPass.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/shaders/CopyShader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/postprocessing/ShaderPass.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.139.2/examples/js/shaders/LuminosityHighPassShader.js"></script>
  
  <meta name="google-site-verification" content="bKn2hLTLLXTef5EmDecqfov8dA-cdLnxiA0dUtdnDvo" />
  <link rel="stylesheet" type="text/css" href="mystyle.css">
  <title>
    andy muehlhausen
  </title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
</head>

<body >
	<div id="threejs-container" style="position: fixed; width: 100%; height: 100vh; top: 0; left: 0; z-index: -1;"></div>
	<div id="content">
    <h1 class="home-title"><span>andy muehlhausen</span></h1>
    <h2>
		<a href="https://www.linkedin.com/in/andymule">linkedin</a> - 
  		<a href="https://github.com/andymule">github</a> - 
		<a href="resume_march_2025.pdf">pdf</a>
		<!-- <hr style="border: none; height: 2px; background-color: rgba(255, 255, 255, 0.5); margin-top: 20px; margin-bottom: 20px; width: 300px; margin-right: auto; margin-right: auto; margin-left: 0;"> -->
    <p class="home-title">
		<strong>Emerging Tech Experience Designer</strong><br />
    <span>My mission is to build meaningful human-to-human interactions that push the boundaries of technology. </span><br />
    <span>I design, lead, and implement immersive interactive experiences involving combinations of computers and physical
        interaction.</span>
	</p>

		<hr style="border: none; height: 2px; background-color: rgba(255, 255, 255, 0.5); margin-top: 20px; margin-bottom: 20px; width: 300px; margin-right: auto; margin-right: auto; margin-left: 0;">

		<p class="home-title">
			<strong>Apple, Vision Products Group</strong><br /> <i>AR Experience Prototyper, 2022 - Present</i> <br />
			<span>I design interactions for emergent products with full stack consideration. <br /> 
			I serve as Experience DRI for successful interactions and work with EE, PD, and ID to ship.</span>
		</p>
		<p class="home-title">
			<strong>Meta, Reality Labs Research</strong><br /> <i>Senior Audio Experience Prototyper, 2020 - 2022</i> <br />
			└ <a href="https://about.fb.com/news/2020/09/facebook-reality-labs-research-future-of-audio/">Audio Presence and Superhuman Hearing Experience Research</a><br />
		</p>
		<p class="home-title">
			<strong>Tobii Eye-Tracking </strong><br /> <i> Mixed Reality Eye-Tracked Interaction Designer, 2018 - 2020</i> <br />
			├ <a href="https://vr.tobii.com/sdk/explore/">Tobii Interactions Showcase</a><br />
			├ <a href="https://vr.tobii.com/sdk/develop/unity/tools/xr-dev-tools/">XR Eye Tracking Dev Tools</a><br />
			├ <a href="https://vr.tobii.com/sdk/develop/unity/tools/gaze-modifier/">Gaze Modifier</a><br />
			├ <a href="https://vr.tobii.com/sdk/learn/eye-behavior/visual-angles/">Explaining Visual Angles</a><br />
			└ <a href="https://vr.tobii.com/sdk/learn/eye-behavior/hardware-accuracy/">Explaining Eye Tracking Accuracy</a><br />
		</p>
		<p class="home-title">
			<strong>Microsoft</strong><br /> 
			<i>Hardware Prototyper @ Incubation Labs, 2016 - 2018 <br /> 
			Audio Experience Prototyper @ HoloLens, 2014 - 2016 </i><br />
			├ <a href="https://github.com/microsoft/MixedRealityToolkit/blob/master/Input/MicStreamSelector/Source/MicStreamSelector.cpp">HoloLens Beamforming Capture Library</a><br />
			├ <a href="https://github.com/reneschulte/HoloToolkit-Unity/blob/master/Assets/HoloToolkit/Input/Scripts/Microphone/MicStream.cs">Unity Hooks for HoloLens Beamforming Library</a><br />
			├ <a href="https://docs.unity3d.com/Manual/VRAudioSpatializer.html">Unity Audio Spatializer Platform</a><br />
			└ <a href="https://www.audiokinetic.com/library/2017.2.10_6745/?source=Help&id=ms_hrtf_plug_in">Wwise MS HRTF Plugin</a><br />
		</p>
		<p>
			<strong>Qualcomm Institute - UCSD Division of Calit2</strong><br /> <i>Research Assistant, 2012 - 2014</i><br />
			└<a href="https://www.youtube.com/watch?v=8bS0Borb-f8">MUGIC, Multi-User Graphics with Interactive Control</a><br />
		</p>
	
		<p><strong>U.S. Patents<br /> 
		</strong>
		
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/11614798">Eye Tracking (through ear canal deformation)</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/20220256304">Environmental Condition Based Spatial Audio Presentation</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10630965">Calibrating a near-eye display</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10674305">Remote multi-dimensional audio</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10694311">Synchronized spatial audio presentation</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10740389">Remembering audio traces of physical actions</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10481856">Volume adjustment on hinged multi-screen device</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10437336">Haptics to identify button regions</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10317505">Composite sound output for network connected devices</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10311543">Virtual object movement</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10249095">Context-based discovery of applications</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/10186086">Augmented reality control of computing device</a> <br />
		├<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/9865091">Localizing devices in augmented reality environment</a> <br />
		└<a href="https://ppubs.uspto.gov/dirsearch-public/print/downloadPdf/9558760">Real-time remodeling of user voice </a> <br />
		</p>
		<p><strong>Education</strong> 
			<br /> University of California, San Diego (MFA), Theatre (Sound Design) &middot; (2011 - 2014) <br /> Purdue University (BS), Computer Science; Minors: Theatre, Physics &middot; (2006 - 2010)</p>

			<hr style="border: none; height: 1px; background-color: rgba(255, 255, 255, 0.5); margin-top: 20px; margin-bottom: 20px; width: 300px; margin-right: auto; margin-right: auto; margin-left: 0;">

<p><strong>Personal Projects</strong><br />
		
	<a href="https://github.com/andymule/nogBasic23">Apple IIe bootable disk for invitation to eggnog party, 2023 </a><br />
	<a href="https://github.com/andymule/flix-space">SwiftPackageManager-only video game to learn swift, 2022 </a><br />
	<a href="https://drive.google.com/drive/folders/1K0drdsZsYUe4FNBmSy0WJmSxi_JVF2IA">AR Music Interaction weekend project, 2022 </a><br />
	<a href="https://github.com/andymule/ESP32DuplexAudioStream">Realtime full duplex wireless comms on ESP32, 2021</a><br />		
	<a href="https://www.facebook.com/events/476285726627950/">Fourth Place of 30 teams, LeetHack Stockholm coding competition, 2020</a><br />
	<a href="https://github.com/andymule/FingerballU">FingerLeague: phone LAN sport, 2019</a><br />
	<a href="https://oshpark.com/profiles/andymule">Tiny Wifi Arduino w/ power, usb, serial, 2018</a><br />
	<a href="https://github.com/andymule/EPD32">Ultra Low-Power E-paper Weather Module, 2018</a><br />
	Sketch-and-Say AI-Assist Drawing, 2017<br />
	Waveform Synthesis RGB LED controller, 2017<br />
	Haptic Vision-Remapping Gauntlet, 2016<br />
  <a href="https://vimeo.com/334830560">kringla heimsins; collab w/ Joshua Tonies, 2014</a><br />
	HTML5 live-synched audio reactive visualizers, 2014<br />
	Sound-Augmented Ping Pong, 2014<br />
	55 Player Theatre Video Game, 2014<br />
	13' DIY Touchscreen/Projection-Tent Game, 2014<br />
	So much music, whole life<br />
</p>

<hr style="border: none; height: 1px; background-color: rgba(255, 255, 255, 0.5); margin-top: 20px; margin-bottom: 20px; width: 300px; margin-right: auto; margin-right: auto; margin-left: 0;">
<p><strong>Personal Project Videos</strong>
<div class="vidz">
  <video src="newvids/nog2-converted.mp4" type="video/mp4"></video>
  <video src="newvids/aicandraw-converted.mp4" type="video/mp4"></video>
  <video src="newvids/ai3.mp4" type="video/mp4"></video>
  <video src="newvids/hallow-converted.mp4" type="video/mp4"></video>
  <video src="newvids/yerba.mp4" type="video/mp4"></video>
  <video src="newvids/ramainstallation-converted.mp4" type="video/mp4"></video>
  <video src="newvids/ballslines22-converted.mp4" type="video/mp4"></video>
  <video src="newvids/gnoPong-converted.mp4" type="video/mp4"></video>
  <video src="newvids/demo-converted.mp4" type="video/mp4"></video>
  <video src="newvids/bingobongo.mp4" type="video/mp4"></video>
  <video src="newvids/html5phones-converted.mp4" type="video/mp4"></video>
  <img src="FL.gif" alt="Animated GIF"> 
  <img src="newvids/resight.png" alt="Resight Visualization">
  <img src="newvids/weather2.png" alt="Weather Data Visualization">
</div>

<br />
<a href="https://www.linkedin.com/in/andymule">linkedin</a> - 
<a href="https://github.com/andymule">github</a> - 
<a href="resume2.pdf">pdf</a>

</h2>
</div>
</body>

<script>
function updateLinkColors() { 
    const links = document.querySelectorAll('a');
    const windowHeight = window.innerHeight;
    const currentTime = Date.now(); // Current time in milliseconds

    links.forEach((link, index) => {
        const linkRect = link.getBoundingClientRect();
        const linkY = linkRect.top;

        // Normalize linkY to be within the range of 0 (top of viewport) to windowHeight (bottom of viewport)
        const normalizedPosition = Math.min(Math.max(linkY, 0), windowHeight);

        // Calculate fraction of the link's position within the viewport
        const fraction = normalizedPosition / windowHeight;

        // Modulate hue based on both position and time to create a chasing rainbow effect
        // The speed factor can be adjusted. Lower values slow down the animation, higher values speed it up.
        const speedFactor = 0.06;
        const hue = (currentTime * speedFactor + fraction * 360) % 360;
        const saturation = 55; // Full saturation for vivid colors
        const lightness = 65;  // Normal lightness

        link.style.color = `hsl(${hue}, ${saturation}%, ${lightness}%)`;
    });

    // Continue the animation
    requestAnimationFrame(updateLinkColors);
}

// Start the animation when the document is ready
document.addEventListener("DOMContentLoaded", function() {
    requestAnimationFrame(updateLinkColors);
});




var contentDiv = document.getElementById('content');
contentDiv.style.transition = 'none';
contentDiv.style.opacity = '0';
setTimeout(function() {
        // After 2 seconds, apply transition and change opacity to 1
        contentDiv.style.transition = 'opacity 3s ease-in-out';
        contentDiv.style.opacity = '1';
}, 1000); 

document.addEventListener("DOMContentLoaded", function() {
  var videos = document.querySelectorAll('.vidz video'); // Select all video elements inside .vidz container
  videos.forEach(function(video) {
    video.setAttribute('playsinline', 'true');
    video.setAttribute('controls', 'true');
    video.setAttribute('muted', 'true');
    video.muted = true; // Mutes the video
    video.setAttribute('autoplay', 'true');
    video.setAttribute('loop', 'true');
    video.addEventListener('loadedmetadata', function() {
      video.currentTime = video.duration / 4;
      video.play().catch(function(error) {
        console.error("Video playback failed: ", error);
      });
    });
  });
});

var composer, bloomPass;
var camera, scene, renderer, geometry, material, mesh, materials, lightSphere;
var prevMouseX = 0, prevMouseY = 0, mouseDX = 0, mouseDY = 0, scrollMomentum = 0;
var clock = new THREE.Clock();
var mouseLight;

// var noiseShader = {
//     uniforms: {
//         "tDiffuse": { value: null },
//         "amount": { value: 0.02 }
//     },
//     vertexShader: /*  TODO vertex shader code */,
//     fragmentShader: /* TODO fragment shader code with noise */
// };

function setupPostProcessing() {
    var renderScene = new THREE.RenderPass(scene, camera);

    bloomPass = new THREE.UnrealBloomPass(
        new THREE.Vector2(window.innerWidth, window.innerHeight),
        1.5, // strength
        0.4, // radius
        0.85 // threshold
    );
    bloomPass.renderToScreen = true;

    composer = new THREE.EffectComposer(renderer);
    
    // var noisePass = new THREE.ShaderPass(noiseShader);
    // composer.addPass(noisePass);
    composer.addPass(renderScene);
    composer.addPass(bloomPass);
}

function createParticles() {
    var particleCount = 1000;
    var particles = new THREE.BufferGeometry();
    var positions = new Float32Array(particleCount * 3);

    for (var i = 0; i < particleCount; i++) {
        positions[i * 3] = (Math.random() * 2 - 1) * 10;
        positions[i * 3 + 1] = (Math.random() * 2 - 1) * 10;
        positions[i * 3 + 2] = (Math.random() * 2 - 1) * 10;
    }

    particles.setAttribute('position', new THREE.BufferAttribute(positions, 3));

    var circleTexture = createCircleTexture();
    var particleMaterial = new THREE.PointsMaterial({
        color: 0xffffff,
        size: 0.2,
        map: circleTexture,
        transparent: true,
        opacity: 0.8,
        blending: THREE.AdditiveBlending,
        depthTest: false
    });

    var particleSystem = new THREE.Points(particles, particleMaterial);
    scene.add(particleSystem);
}


function handleInput(event, scaleX = 1) {
    var tempX = (event.clientX - window.innerWidth / 2) * 0.0002;
    var tempY = (event.clientY - window.innerHeight / 2) * 0.0002;
    mouseDX += tempX - prevMouseX;
    mouseDY += tempY - prevMouseY;
    prevMouseX = tempX;
    prevMouseY = tempY;

    // Update light position to follow mouse
    var mouseLightX = (event.clientX / window.innerWidth) * 20 - 10
    var mouseLightY = -(event.clientY / window.innerHeight) * 20 + 10
    mouseLight.position.set(mouseLightX, mouseLightY , 0.5);
    var newPosition = new THREE.Vector3(mouseLightX, mouseLightY, 8);
    customShaderMaterial.uniforms.lightPosition.value.copy(newPosition);
    
    var mouseX = (event.clientX / window.innerWidth);
    var mouseY = -(event.clientY / window.innerHeight);
    lightSphere.position.set((mouseX * 6 - 3) * scaleX, mouseY * 4 + 2, -2);
}

function handleTouchInput(event) {
    event.preventDefault();
    var touch = event.touches[0];
    handleInput(touch, 0.33);
}

function setupDynamicLighting() {
    var ambientLight = new THREE.AmbientLight(0x404040);
    scene.add(ambientLight);

    var dynamicLight = new THREE.PointLight(0xff0000, 1, 50);
    dynamicLight.position.set(5, 5, 5);
    scene.add(dynamicLight);

    var lightColor = { r: 255, g: 0, b: 0 };
    var colorChangeSpeed = 0.01;

    function updateLightColor() {
        lightColor.g += colorChangeSpeed;
        if (lightColor.g > 255 || lightColor.g < 0) {
            colorChangeSpeed = -colorChangeSpeed;
        }
        dynamicLight.color.setRGB(lightColor.r / 255, lightColor.g / 255, lightColor.b / 255);
        requestAnimationFrame(updateLightColor);
    }

    updateLightColor();
}

function init() {
    setupScene();
    setupScrollMomentum();
    setupPostProcessing();
    // createParticles();
    // setupDynamicLighting();

    const initialMouseX = (window.innerWidth);
    const initialMouseY = (-window.innerHeight);

    // Convert the initial mouse position to 3D coordinates
    var initialMouseLightX = (initialMouseX / window.innerWidth) * 20 - 10;
    var initialMouseLightY = -(initialMouseY / window.innerHeight) * 20 + 10;
    mouseLight.position.set(initialMouseLightX, initialMouseLightY, 0.5);
    var initialNewPosition = new THREE.Vector3(initialMouseLightX, initialMouseLightY, 8);
    customShaderMaterial.uniforms.lightPosition.value.copy(initialNewPosition);
    var initialMouse3DX = (initialMouseX / window.innerWidth);
    var initialMouse3DY = -(initialMouseY / window.innerHeight);
    lightSphere.position.set(initialMouse3DX * 6 - 3, initialMouse3DY * 4 + 2, -2);
    document.addEventListener('mousemove', handleInput, false);
    document.addEventListener('touchmove', handleTouchInput, false);
    // document.addEventListener('touchstart', handleTouchInput, false);  // Ensure initial touch is handled
    // document.addEventListener('touchend', (event) => event.preventDefault(), false); // Prevent default scroll behavior
    window.addEventListener('resize', onWindowResize, false);
}

function updateRendererSize() {
    var container = document.getElementById('threejs-container');
    renderer.setSize(container.offsetWidth, container.offsetHeight);
    camera.aspect = container.offsetWidth / container.offsetHeight;
    camera.updateProjectionMatrix();
}

function onWindowResize() {
    if (!isMobileDevice()) {
        updateRendererSize();
    }
}

function isMobileDevice() {
    return /Mobi|Android/i.test(navigator.userAgent);
}

function createCircleTexture() {
    var size = 128;
    var canvas = document.createElement('canvas');
    canvas.width = size;
    canvas.height = size;

    var context = canvas.getContext('2d');
    context.beginPath();
    context.arc(size / 2, size / 2, size / 2, 0, Math.PI * 2);
    context.closePath();
    context.fillStyle = 'white';
    context.fill();

    var texture = new THREE.CanvasTexture(canvas);
    return texture;
}

function setupScene() {
    var container = document.getElementById('threejs-container');
    
    camera = new THREE.PerspectiveCamera(70, container.offsetWidth / container.offsetHeight, 0.01, 50);
    camera.position.z = 1;
    scene = new THREE.Scene();
    geometry = new THREE.SphereGeometry(3, 3, 3);
    mesh = new THREE.Mesh(geometry, customShaderMaterial);
    mesh.position.set(0, 0, -5);
    scene.add(mesh);
    // scene.background = new THREE.Color(0x0f0f0f);

    // Set background to a gradient
    var canvas = document.createElement('canvas');
    canvas.width = 1;
    canvas.height = 1024; // Increase height for a smoother gradient
    var context = canvas.getContext('2d');
    var gradient = context.createLinearGradient(0, 0, 0, 1024); // Adjust gradient height accordingly
    gradient.addColorStop(0, '#101010');
    gradient.addColorStop(0.5, '#202040');
    gradient.addColorStop(1, '#101010');
    context.fillStyle = gradient;
    context.fillRect(0, 0, 1, 1024); // Adjust fill height accordingly
    var backgroundTexture = new THREE.CanvasTexture(canvas);
    scene.background = backgroundTexture;

    mouseLight = new THREE.PointLight(0xffffff, 1, 100);
    scene.add(mouseLight);

    var lightSphereGeometry = new THREE.SphereGeometry(0.05, 16, 16);
    var lightSphereMaterial = new THREE.MeshBasicMaterial({ color: 0xffffff });
    lightSphere = new THREE.Mesh(lightSphereGeometry, lightSphereMaterial);
    scene.add(lightSphere);

    renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
    renderer.dithering = true;
    renderer.outputEncoding = THREE.LinearEncoding;
    customShaderMaterial.dithering = true;
    renderer.setPixelRatio(window.devicePixelRatio); // Adjust pixel ratio for higher quality
    renderer.setSize(container.offsetWidth, container.offsetHeight);
    container.appendChild(renderer.domElement);
}

function setupScrollMomentum() {
    window.onscroll = function () {
        let scrollDelta = window.scrollY - (window.lastScrollY || 0);
        window.lastScrollY = window.scrollY;
        scrollMomentum += scrollDelta * 0.00015;
    };
}

function animate() {
    requestAnimationFrame(animate);

    let delta = clock.getDelta();
    mesh.rotation.x += (0.1 * delta) + mouseDX;
    mesh.rotation.y += (0.1 * delta) + mouseDY;
    mesh.rotation.z += scrollMomentum;

    // Dampen the momentum
    mouseDX *= 0.95;
    mouseDY *= 0.95;
    scrollMomentum *= 0.95;

    // renderer.render(scene, camera);
    composer.render();
}

// Initialize and animate the scene after the document is fully loaded
document.addEventListener('DOMContentLoaded', function () {
    init();
    animate();
});

var customShaderMaterial = new THREE.ShaderMaterial({
    uniforms: {
        lightPosition: { value: new THREE.Vector3() }
    },
    vertexShader: `
        precision highp float;
        varying vec3 vNormal;
        varying vec3 vViewPosition;

        void main() {
            vNormal = normalize(normalMatrix * normal);
            vec4 mvPosition = modelViewMatrix * vec4(position, 1.0);
            vViewPosition = -mvPosition.xyz;
            gl_Position = projectionMatrix * mvPosition;
        }
    `,
    fragmentShader: `
        precision highp float;
        uniform vec3 lightPosition;
        varying vec3 vNormal;
        varying vec3 vViewPosition;

        float rand(vec2 co) {
           return fract(sin(dot(co.xy, vec2(12.9898, 78.233))) * 43758.5453);
        }

        void main() {
            // Normal material contribution
            vec3 normalColor = normalize(vNormal) * 0.5 + 0.5;

            // Phong material contribution
            vec3 lightDirection = normalize(lightPosition - vViewPosition);
            float specularStrength = 0.5;
            vec3 viewDirection = normalize(vViewPosition);
            vec3 halfVector = normalize(lightDirection + viewDirection);
            float specular = pow(max(dot(vNormal, halfVector), 0.0), 32.0);
            vec3 phongColor = vec3(0.1, 0.1, 0.1) + vec3(0.7, 0.7, 0.7) * max(dot(vNormal, lightDirection), 0.0) + specularStrength * specular;

            // Blend the two contributions
            vec3 finalColor = mix(normalColor, phongColor, 0.6);
            float dither = rand(gl_FragCoord.xy) * (1.0 / 255.0);
            finalColor.rgb += dither;
            gl_FragColor = vec4(finalColor, 1.0);
        }
    `,
    side: THREE.DoubleSide
});



</script>
</html>